"""
Sanskrit Solver Model for R-Zero Co-evolutionary Loop.

This module adapts R-Zero's Solver model to improve Sanskrit rule application accuracy
through co-evolutionary training with the Challenger model.
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import vllm
from transformers import AutoTokenizer

from .r_zero_integration import (
    SanskritProblem, SanskritSolution, SanskritProblemType,
    SanskritGrammaticalValidator, SanskritReasoningMetrics
)
from .r_zero_config import SanskritRZeroConfig
from .sanskrit_reward_function import SanskritRewardCalculator


logger = logging.getLogger(__name__)


@dataclass
class SolverConfig:
    """Configuration for Sanskrit Solver model."""
    model_path: str = "Qwen/Qwen2.5-7B-Instruct"
    temperature: float = 1.0
    top_p: float = 1.0
    top_k: int = 40
    max_tokens: int = 4096
    num_samples: int = 10
    gpu_memory_utilization: float = 0.85
    seed: int = 42


class SanskritSolver:
    """
    Sanskrit Solver model that learns to solve Sanskrit grammatical problems.
    
    This model improves its Sanskrit reasoning capabilities through training
    on problems generated by the Challenger model.
    """
    
    def __init__(self, 
                 config: SolverConfig,
                 validator: Optional[SanskritGrammaticalValidator] = None,
                 storage_path: str = "./r_zero_storage"):
        """
        Initialize the Sanskrit Solver.
        
        Args:
            config: Solver configuration
            validator: Sanskrit grammatical validator
            storage_path: Path for storing results
        """
        self.config = config
        self.validator = validator
        self.storage_path = Path(storage_path)
        self.results_path = self.storage_path / "solver_results"
        self.results_path.mkdir(parents=True, exist_ok=True)
        
        # Initialize model
        self.tokenizer = None
        self.model = None
        self._initialize_model()
        
        # Initialize metrics and reward calculator
        self.metrics = SanskritReasoningMetrics(validator) if validator else None
        self.reward_calculator = SanskritRewardCalculator(validator)
        
        # Problem-solving templates
        self._initialize_templates()
    
    def _initialize_model(self):
        """Initialize the VLLM model and tokenizer."""
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_path)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            if self.tokenizer.pad_token_id is None:
                self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
            
            self.model = vllm.LLM(
                model=self.config.model_path,
                tokenizer=self.config.model_path,
                gpu_memory_utilization=self.config.gpu_memory_utilization,
                seed=self.config.seed,
            )
            logger.info(f"Initialized Solver model: {self.config.model_path}")
        except Exception as e:
            logger.error(f"Failed to initialize Solver model: {e}")
            raise
    
    def _initialize_templates(self):
        """Initialize problem-solving templates."""
        self.system_prompt = """You are an expert Sanskrit grammarian with deep knowledge of Pāṇinian grammar.

Your task is to solve Sanskrit grammatical problems systematically and accurately.

For each problem:
1. Analyze the input carefully
2. Apply relevant Pāṇini sūtras and grammatical rules
3. Show your reasoning step-by-step
4. Provide the final answer clearly

Always format your final answer within \\boxed{} tags.

Key principles to follow:
- Apply sandhi rules correctly for phonological transformations
- Identify morphological components (dhātu, pratyaya) accurately
- Use systematic derivation processes (śabda-prakriyā)
- Analyze compounds (samāsa) by type and structure
- Validate grammatical correctness using traditional rules
- Reference relevant sūtra numbers when applicable"""

        self.problem_type_instructions = {
            SanskritProblemType.SANDHI_APPLICATION: 
                "Apply sandhi rules to combine the given elements. Show the transformation step-by-step.",
            
            SanskritProblemType.MORPHOLOGICAL_ANALYSIS:
                "Break down the word into its morphological components. Identify root, suffixes, and grammatical categories.",
            
            SanskritProblemType.WORD_DERIVATION:
                "Provide complete śabda-prakriyā showing derivation from root to final form with sūtra citations.",
            
            SanskritProblemType.COMPOUND_ANALYSIS:
                "Analyze the compound structure. Identify the samāsa type and constituent elements.",
            
            SanskritProblemType.RULE_APPLICATION:
                "Apply the specified Pāṇini rule to the given input. Show the transformation clearly.",
            
            SanskritProblemType.GRAMMATICAL_VALIDATION:
                "Check grammatical correctness. If incorrect, provide the correct form with explanation.",
        }
    
    def solve_problems(self, problems: List[SanskritProblem]) -> List[SanskritSolution]:
        """
        Solve a list of Sanskrit problems.
        
        Args:
            problems: List of Sanskrit problems to solve
            
        Returns:
            List of solutions
        """
        logger.info(f"Solving {len(problems)} Sanskrit problems")
        
        solutions = []
        for i, problem in enumerate(problems):
            try:
                solution = self.solve_single_problem(problem)
                solutions.append(solution)
                
                if (i + 1) % 10 == 0:
                    logger.info(f"Solved {i + 1}/{len(problems)} problems")
                    
            except Exception as e:
                logger.error(f"Error solving problem {problem.id}: {e}")
                # Create fallback solution
                solutions.append(SanskritSolution(
                    problem_id=problem.id,
                    solution_text="Error in processing",
                    confidence=0.0,
                    metadata={"error": str(e)}
                ))
        
        logger.info(f"Completed solving {len(solutions)} problems")
        return solutions
    
    def solve_single_problem(self, problem: SanskritProblem) -> SanskritSolution:
        """
        Solve a single Sanskrit problem.
        
        Args:
            problem: Sanskrit problem to solve
            
        Returns:
            Solution to the problem
        """
        # Create problem-specific prompt
        user_prompt = self._create_solving_prompt(problem)
        
        # Generate solutions using the model
        generated_responses = self._generate_solutions(user_prompt)
        
        # Process and evaluate responses
        best_solution = self._select_best_solution(problem, generated_responses)
        
        return best_solution
    
    def _create_solving_prompt(self, problem: SanskritProblem) -> str:
        """Create prompt for solving a specific problem."""
        type_instruction = self.problem_type_instructions.get(
            problem.type, 
            "Analyze the Sanskrit input and provide appropriate solution."
        )
        
        context_info = ""
        if problem.context:
            context_info = f"\nContext: {problem.context}"
        
        sutra_info = ""
        if problem.sutra_references:
            sutra_info = f"\nRelevant sūtras: {', '.join(problem.sutra_references)}"
        
        return f"""Problem Type: {problem.type.value}
Difficulty: {problem.difficulty.value}

Task: {type_instruction}

Input: {problem.input_text}
{context_info}
{sutra_info}

Please solve this step-by-step and provide your final answer within \\boxed{{}} tags."""
    
    def _generate_solutions(self, user_prompt: str) -> List[str]:
        """Generate solutions using the VLLM model."""
        chat = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        if self.tokenizer.chat_template:
            prompt = self.tokenizer.apply_chat_template(
                chat, 
                tokenize=False,
                add_generation_prompt=True, 
                add_special_tokens=True
            )
        else:
            prompt = f"system: {chat[0]['content']}\nuser: {chat[1]['content']}"
        
        sample_params = vllm.SamplingParams(
            max_tokens=self.config.max_tokens,
            temperature=self.config.temperature,
            top_p=self.config.top_p,
            top_k=self.config.top_k,
            n=self.config.num_samples,
            stop_token_ids=[self.tokenizer.eos_token_id],
        )
        
        completions = self.model.generate([prompt], sampling_params=sample_params)
        
        return [output.text for output in completions[0].outputs]
    
    def _select_best_solution(self, 
                             problem: SanskritProblem, 
                             responses: List[str]) -> SanskritSolution:
        """Select the best solution from multiple responses."""
        if not responses:
            return SanskritSolution(
                problem_id=problem.id,
                solution_text="No solution generated",
                confidence=0.0
            )
        
        # Extract boxed answers and evaluate
        solutions_with_scores = []
        
        for response in responses:
            # Extract boxed answer
            boxed_answer = self._extract_boxed_answer(response)
            if not boxed_answer:
                boxed_answer = response.strip()
            
            # Calculate reward/score
            if problem.expected_output:
                reward = self.reward_calculator.calculate_reward(
                    boxed_answer, problem.expected_output, problem
                )
                score = reward.overall_score
            else:
                # Use grammatical validation as fallback
                score = self._evaluate_solution_quality(boxed_answer, problem)
            
            solutions_with_scores.append({
                'response': response,
                'answer': boxed_answer,
                'score': score
            })
        
        # Find consensus answer (most common among high-scoring solutions)
        high_scoring = [s for s in solutions_with_scores if s['score'] > 0.5]
        if not high_scoring:
            high_scoring = solutions_with_scores
        
        # Group by answer and find majority
        answer_groups = {}
        for sol in high_scoring:
            answer = sol['answer']
            if answer not in answer_groups:
                answer_groups[answer] = []
            answer_groups[answer].append(sol)
        
        # Select answer with highest average score
        best_answer = None
        best_score = 0.0
        best_response = ""
        
        for answer, group in answer_groups.items():
            avg_score = sum(s['score'] for s in group) / len(group)
            if avg_score > best_score:
                best_score = avg_score
                best_answer = answer
                best_response = group[0]['response']  # Take first response for this answer
        
        # Extract reasoning steps
        reasoning_steps = self._extract_reasoning_steps(best_response)
        
        return SanskritSolution(
            problem_id=problem.id,
            solution_text=best_answer or "No valid solution",
            confidence=best_score,
            reasoning_steps=reasoning_steps,
            metadata={
                "num_responses": len(responses),
                "consensus_size": len(answer_groups.get(best_answer, [])),
                "model_path": self.config.model_path
            }
        )
    
    def _extract_boxed_answer(self, response: str) -> Optional[str]:
        """Extract answer from \\boxed{} tags."""
        import re
        
        # Look for \\boxed{...} pattern
        boxed_pattern = r'\\boxed\{([^}]*)\}'
        matches = re.findall(boxed_pattern, response)
        
        if matches:
            return matches[-1].strip()  # Take the last match
        
        # Fallback: look for other answer indicators
        answer_patterns = [
            r'Answer:\s*(.+?)(?:\n|$)',
            r'Final answer:\s*(.+?)(?:\n|$)',
            r'Solution:\s*(.+?)(?:\n|$)',
        ]
        
        for pattern in answer_patterns:
            matches = re.findall(pattern, response, re.IGNORECASE)
            if matches:
                return matches[-1].strip()
        
        return None
    
    def _extract_reasoning_steps(self, response: str) -> List[str]:
        """Extract reasoning steps from response."""
        steps = []
        
        # Split by common step indicators
        step_indicators = ['Step', 'step', '1.', '2.', '3.', 'First', 'Next', 'Then', 'Finally']
        
        lines = response.split('\n')
        current_step = ""
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Check if line starts a new step
            if any(line.startswith(indicator) for indicator in step_indicators):
                if current_step:
                    steps.append(current_step.strip())
                current_step = line
            else:
                if current_step:
                    current_step += " " + line
                else:
                    current_step = line
        
        # Add final step
        if current_step:
            steps.append(current_step.strip())
        
        return steps[:10]  # Limit to 10 steps
    
    def _evaluate_solution_quality(self, solution: str, problem: SanskritProblem) -> float:
        """Evaluate solution quality when no ground truth is available."""
        if not solution:
            return 0.0
        
        score = 0.0
        
        # Basic format check
        if solution.strip():
            score += 0.2
        
        # Sanskrit content check
        import re
        sanskrit_pattern = r'[अ-ह्ा-ृे-ौं-ःऽ]|[aāiīuūṛṝḷḹeaioauṃḥ]'
        if re.search(sanskrit_pattern, solution):
            score += 0.3
        
        # Problem-specific checks
        if problem.type == SanskritProblemType.SANDHI_APPLICATION:
            if '→' in solution or 'result' in solution.lower():
                score += 0.2
        elif problem.type == SanskritProblemType.MORPHOLOGICAL_ANALYSIS:
            if any(marker in solution for marker in ['root', 'suffix', '+', '(']):
                score += 0.2
        
        # Grammatical validation if available
        if self.validator:
            try:
                validation = self.validator.validate_sanskrit_text(solution)
                score += validation.get('confidence', 0.0) * 0.3
            except:
                pass
        
        return min(1.0, score)
    
    def evaluate_performance(self, 
                           problems: List[SanskritProblem],
                           solutions: List[SanskritSolution]) -> Dict[str, float]:
        """
        Evaluate Solver performance on a set of problems.
        
        Args:
            problems: List of problems
            solutions: List of solutions
            
        Returns:
            Performance metrics by problem type
        """
        if len(problems) != len(solutions):
            logger.error("Mismatch between problems and solutions count")
            return {}
        
        # Group by problem type
        type_performance = {}
        
        for problem, solution in zip(problems, solutions):
            problem_type = problem.type.value
            
            if problem_type not in type_performance:
                type_performance[problem_type] = []
            
            # Calculate performance score
            if problem.expected_output:
                reward = self.reward_calculator.calculate_reward(
                    solution.solution_text, problem.expected_output, problem
                )
                score = reward.overall_score
            else:
                score = solution.confidence
            
            type_performance[problem_type].append(score)
        
        # Calculate averages
        avg_performance = {}
        for problem_type, scores in type_performance.items():
            avg_performance[problem_type] = sum(scores) / len(scores) if scores else 0.0
        
        # Overall performance
        all_scores = [score for scores in type_performance.values() for score in scores]
        avg_performance['overall'] = sum(all_scores) / len(all_scores) if all_scores else 0.0
        
        logger.info(f"Solver performance: {avg_performance}")
        return avg_performance
    
    def save_results(self, 
                    problems: List[SanskritProblem],
                    solutions: List[SanskritSolution],
                    filename: str) -> str:
        """Save solving results to file."""
        filepath = self.results_path / f"{filename}.json"
        
        results = []
        for problem, solution in zip(problems, solutions):
            results.append({
                "problem": problem.to_r_zero_format(),
                "solution": {
                    "problem_id": solution.problem_id,
                    "solution_text": solution.solution_text,
                    "confidence": solution.confidence,
                    "reasoning_steps": solution.reasoning_steps,
                    "rule_applications": solution.rule_applications,
                    "validation_results": solution.validation_results,
                    "metadata": solution.metadata
                }
            })
        
        # Add metadata
        data = {
            "results": results,
            "metadata": {
                "solver_model": self.config.model_path,
                "total_problems": len(problems),
                "total_solutions": len(solutions),
                "generation_params": {
                    "temperature": self.config.temperature,
                    "top_p": self.config.top_p,
                    "num_samples": self.config.num_samples
                }
            }
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Saved results to {filepath}")
        return str(filepath)


def create_sanskrit_solver(config_path: Optional[str] = None) -> SanskritSolver:
    """
    Create a Sanskrit Solver instance.
    
    Args:
        config_path: Optional path to configuration file
        
    Returns:
        Configured SanskritSolver
    """
    # Load R-Zero config
    if config_path and Path(config_path).exists():
        r_zero_config = SanskritRZeroConfig.load_from_yaml(config_path)
    else:
        r_zero_config = SanskritRZeroConfig()
    
    # Create solver config
    solver_config = SolverConfig(
        temperature=r_zero_config.temperature,
        top_p=r_zero_config.top_p,
        seed=42
    )
    
    # Initialize validator (simplified for now)
    from .panini_engine import PaniniRuleEngine
    from .morphological_analyzer import SanskritMorphologicalAnalyzer
    from .tokenizer import SanskritTokenizer
    
    tokenizer = SanskritTokenizer()
    rule_engine = PaniniRuleEngine(tokenizer)
    morphological_analyzer = SanskritMorphologicalAnalyzer(tokenizer, rule_engine)
    
    validator = SanskritGrammaticalValidator(rule_engine, morphological_analyzer)
    
    return SanskritSolver(
        config=solver_config,
        validator=validator,
        storage_path=r_zero_config.storage_path
    )