"""
Sanskrit Corpus-based Validation and Scoring.

This module provides validation and scoring mechanisms for Sanskrit reasoning
using traditional Sanskrit corpora and grammatical texts. It supports:

- Sandhi transformation validation
- Morphological analysis validation  
- Word derivation validation
- Compound analysis validation
- Rule compliance checking
- Linguistic validity assessment
- Corpus quality validation

The validator uses curated Sanskrit examples to evaluate the accuracy and
correctness of Sanskrit reasoning solutions generated by the R-Zero system.
"""

import json
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
from enum import Enum
from datetime import datetime

from .r_zero_integration import SanskritProblem, SanskritSolution, SanskritProblemType
from .sanskrit_reward_function import SanskritRewardCalculator


logger = logging.getLogger(__name__)


class CorpusType(Enum):
    """Types of Sanskrit corpora for validation."""
    SANDHI_EXAMPLES = "sandhi_examples"
    MORPHOLOGICAL_FORMS = "morphological_forms"
    DERIVATION_EXAMPLES = "derivation_examples"
    COMPOUND_EXAMPLES = "compound_examples"
    CLASSICAL_TEXTS = "classical_texts"


@dataclass
class CorpusEntry:
    """Entry in a Sanskrit corpus."""
    id: str
    source_text: str
    target_text: str
    grammatical_analysis: Dict[str, Any]
    sutra_references: List[str] = field(default_factory=list)
    difficulty_level: str = "INTERMEDIATE"
    corpus_type: CorpusType = CorpusType.SANDHI_EXAMPLES
    metadata: Dict[str, Any] = field(default_factory=dict)


class SanskritCorpusValidator:
    """
    Validator that uses Sanskrit corpora for validation and scoring.
    
    This class provides comprehensive validation against traditional Sanskrit
    grammatical examples and classical texts.
    """
    
    def __init__(self, corpus_path: str = "./sanskrit_corpus"):
        """
        Initialize the corpus validator.
        
        Args:
            corpus_path: Path to Sanskrit corpus directory
        """
        self.corpus_path = Path(corpus_path)
        self.corpus_path.mkdir(parents=True, exist_ok=True)
        
        # Load corpora
        self.corpora: Dict[CorpusType, List[CorpusEntry]] = {}
        self._initialize_corpora()
        
        # Initialize reward calculator
        self.reward_calculator = SanskritRewardCalculator()
        
        logger.info(f"Initialized Sanskrit corpus validator with {sum(len(corpus) for corpus in self.corpora.values())} entries")
    
    def _initialize_corpora(self):
        """Initialize Sanskrit corpora with example data."""
        # Initialize each corpus type
        for corpus_type in CorpusType:
            self.corpora[corpus_type] = []
        
        # Load existing corpora or create sample data
        self._load_or_create_sandhi_corpus()
        self._load_or_create_morphology_corpus()
        self._load_or_create_derivation_corpus()
        self._load_or_create_compound_corpus()
    
    def _load_or_create_sandhi_corpus(self):
        """Load or create sandhi examples corpus."""
        corpus_file = self.corpus_path / "sandhi_examples.json"
        
        if corpus_file.exists():
            try:
                with open(corpus_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                for entry_data in data:
                    entry = CorpusEntry(
                        id=entry_data['id'],
                        source_text=entry_data['source_text'],
                        target_text=entry_data['target_text'],
                        grammatical_analysis=entry_data.get('grammatical_analysis', {}),
                        sutra_references=entry_data.get('sutra_references', []),
                        corpus_type=CorpusType.SANDHI_EXAMPLES,
                        metadata=entry_data.get('metadata', {})
                    )
                    self.corpora[CorpusType.SANDHI_EXAMPLES].append(entry)
                
                logger.info(f"Loaded {len(self.corpora[CorpusType.SANDHI_EXAMPLES])} sandhi examples")
                return
            except Exception as e:
                logger.warning(f"Failed to load sandhi corpus: {e}")
        
        # Create sample sandhi corpus
        sandhi_examples = [
            {
                'id': 'sandhi_001',
                'source_text': 'rāma + iti',
                'target_text': 'rāmeti',
                'grammatical_analysis': {
                    'rule_type': 'vowel_sandhi',
                    'transformation': 'a + i → e'
                },
                'sutra_references': ['6.1.87'],
                'metadata': {'difficulty': 'BEGINNER', 'frequency': 'common'}
            },
            {
                'id': 'sandhi_002',
                'source_text': 'dharma + artha',
                'target_text': 'dharmārtha',
                'grammatical_analysis': {
                    'rule_type': 'vowel_sandhi',
                    'transformation': 'a + a → ā'
                },
                'sutra_references': ['6.1.101'],
                'metadata': {'difficulty': 'BEGINNER', 'frequency': 'common'}
            },
            {
                'id': 'sandhi_003',
                'source_text': 'hari + īśa',
                'target_text': 'harīśa',
                'grammatical_analysis': {
                    'rule_type': 'vowel_sandhi',
                    'transformation': 'i + ī → ī'
                },
                'sutra_references': ['6.1.101'],
                'metadata': {'difficulty': 'INTERMEDIATE', 'frequency': 'moderate'}
            },
            {
                'id': 'sandhi_004',
                'source_text': 'guru + upadeśa',
                'target_text': 'gurupadeśa',
                'grammatical_analysis': {
                    'rule_type': 'vowel_sandhi',
                    'transformation': 'u + u → u'
                },
                'sutra_references': ['6.1.101'],
                'metadata': {'difficulty': 'INTERMEDIATE', 'frequency': 'moderate'}
            },
            {
                'id': 'sandhi_005',
                'source_text': 'pitṛ + ṛṇa',
                'target_text': 'pitṝṇa',
                'grammatical_analysis': {
                    'rule_type': 'vowel_sandhi',
                    'transformation': 'ṛ + ṛ → ṝ'
                },
                'sutra_references': ['6.1.101'],
                'metadata': {'difficulty': 'ADVANCED', 'frequency': 'rare'}
            }
        ]
        
        for example in sandhi_examples:
            entry = CorpusEntry(
                id=example['id'],
                source_text=example['source_text'],
                target_text=example['target_text'],
                grammatical_analysis=example['grammatical_analysis'],
                sutra_references=example['sutra_references'],
                corpus_type=CorpusType.SANDHI_EXAMPLES,
                difficulty_level=example['metadata']['difficulty'],
                metadata=example['metadata']
            )
            self.corpora[CorpusType.SANDHI_EXAMPLES].append(entry)
        
        # Save corpus
        self._save_corpus(CorpusType.SANDHI_EXAMPLES, sandhi_examples)
        logger.info(f"Created sandhi corpus with {len(sandhi_examples)} examples")
    
    def _load_or_create_morphology_corpus(self):
        """Load or create morphological analysis corpus."""
        morphology_examples = [
            {
                'id': 'morph_001',
                'source_text': 'gacchati',
                'target_text': 'gam(ROOT) + ti(PRESENT_3SG)',
                'grammatical_analysis': {
                    'root': 'gam',
                    'suffix': 'ti',
                    'person': '3',
                    'number': 'singular',
                    'tense': 'present'
                },
                'sutra_references': ['3.4.78'],
                'metadata': {'difficulty': 'BEGINNER', 'word_class': 'verb'}
            },
            {
                'id': 'morph_002',
                'source_text': 'karoti',
                'target_text': 'kṛ(ROOT) + oti(PRESENT_3SG)',
                'grammatical_analysis': {
                    'root': 'kṛ',
                    'suffix': 'oti',
                    'person': '3',
                    'number': 'singular',
                    'tense': 'present'
                },
                'sutra_references': ['3.4.78'],
                'metadata': {'difficulty': 'BEGINNER', 'word_class': 'verb'}
            },
            {
                'id': 'morph_003',
                'source_text': 'rāmasya',
                'target_text': 'rāma(STEM) + sya(GEN_SG)',
                'grammatical_analysis': {
                    'stem': 'rāma',
                    'suffix': 'sya',
                    'case': 'genitive',
                    'number': 'singular',
                    'gender': 'masculine'
                },
                'sutra_references': ['4.1.2'],
                'metadata': {'difficulty': 'INTERMEDIATE', 'word_class': 'noun'}
            }
        ]
        
        for example in morphology_examples:
            entry = CorpusEntry(
                id=example['id'],
                source_text=example['source_text'],
                target_text=example['target_text'],
                grammatical_analysis=example['grammatical_analysis'],
                sutra_references=example['sutra_references'],
                corpus_type=CorpusType.MORPHOLOGICAL_FORMS,
                difficulty_level=example['metadata']['difficulty'],
                metadata=example['metadata']
            )
            self.corpora[CorpusType.MORPHOLOGICAL_FORMS].append(entry)
        
        self._save_corpus(CorpusType.MORPHOLOGICAL_FORMS, morphology_examples)
        logger.info(f"Created morphology corpus with {len(morphology_examples)} examples")
    
    def _load_or_create_derivation_corpus(self):
        """Load or create word derivation corpus."""
        derivation_examples = [
            {
                'id': 'deriv_001',
                'source_text': 'gam + ti',
                'target_text': 'gam → gacch → gacchati',
                'grammatical_analysis': {
                    'root': 'gam',
                    'suffix': 'ti',
                    'derivation_steps': [
                        'gam (root)',
                        'gacch (strengthened)',
                        'gacchati (with suffix)'
                    ]
                },
                'sutra_references': ['7.3.76', '3.4.78'],
                'metadata': {'difficulty': 'INTERMEDIATE', 'derivation_type': 'present_tense'}
            },
            {
                'id': 'deriv_002',
                'source_text': 'kṛ + tavya',
                'target_text': 'kṛ → kar → kartavya',
                'grammatical_analysis': {
                    'root': 'kṛ',
                    'suffix': 'tavya',
                    'derivation_steps': [
                        'kṛ (root)',
                        'kar (strengthened)',
                        'kartavya (with suffix)'
                    ]
                },
                'sutra_references': ['7.3.84', '3.1.96'],
                'metadata': {'difficulty': 'ADVANCED', 'derivation_type': 'gerundive'}
            }
        ]
        
        for example in derivation_examples:
            entry = CorpusEntry(
                id=example['id'],
                source_text=example['source_text'],
                target_text=example['target_text'],
                grammatical_analysis=example['grammatical_analysis'],
                sutra_references=example['sutra_references'],
                corpus_type=CorpusType.DERIVATION_EXAMPLES,
                difficulty_level=example['metadata']['difficulty'],
                metadata=example['metadata']
            )
            self.corpora[CorpusType.DERIVATION_EXAMPLES].append(entry)
        
        self._save_corpus(CorpusType.DERIVATION_EXAMPLES, derivation_examples)
        logger.info(f"Created derivation corpus with {len(derivation_examples)} examples")
    
    def _load_or_create_compound_corpus(self):
        """Load or create compound analysis corpus."""
        compound_examples = [
            {
                'id': 'comp_001',
                'source_text': 'rājapuruṣa',
                'target_text': 'rāja + puruṣa (tatpuruṣa)',
                'grammatical_analysis': {
                    'compound_type': 'tatpuruṣa',
                    'first_member': 'rāja',
                    'second_member': 'puruṣa',
                    'relationship': 'genitive_tatpuruṣa'
                },
                'sutra_references': ['2.1.36'],
                'metadata': {'difficulty': 'INTERMEDIATE', 'compound_class': 'tatpuruṣa'}
            },
            {
                'id': 'comp_002',
                'source_text': 'nīlotpala',
                'target_text': 'nīla + utpala (karmadhāraya)',
                'grammatical_analysis': {
                    'compound_type': 'karmadhāraya',
                    'first_member': 'nīla',
                    'second_member': 'utpala',
                    'relationship': 'adjectival_qualification'
                },
                'sutra_references': ['2.1.57'],
                'metadata': {'difficulty': 'INTERMEDIATE', 'compound_class': 'karmadhāraya'}
            },
            {
                'id': 'comp_003',
                'source_text': 'pitāmaha',
                'target_text': 'pitṛ + maha (tatpuruṣa)',
                'grammatical_analysis': {
                    'compound_type': 'tatpuruṣa',
                    'first_member': 'pitṛ',
                    'second_member': 'maha',
                    'relationship': 'genitive_tatpuruṣa'
                },
                'sutra_references': ['2.1.36'],
                'metadata': {'difficulty': 'ADVANCED', 'compound_class': 'tatpuruṣa'}
            }
        ]
        
        for example in compound_examples:
            entry = CorpusEntry(
                id=example['id'],
                source_text=example['source_text'],
                target_text=example['target_text'],
                grammatical_analysis=example['grammatical_analysis'],
                sutra_references=example['sutra_references'],
                corpus_type=CorpusType.COMPOUND_EXAMPLES,
                difficulty_level=example['metadata']['difficulty'],
                metadata=example['metadata']
            )
            self.corpora[CorpusType.COMPOUND_EXAMPLES].append(entry)
        
        self._save_corpus(CorpusType.COMPOUND_EXAMPLES, compound_examples)
        logger.info(f"Created compound corpus with {len(compound_examples)} examples")
    
    def _save_corpus(self, corpus_type: CorpusType, data: List[Dict]):
        """Save corpus data to file."""
        corpus_file = self.corpus_path / f"{corpus_type.value}.json"
        try:
            with open(corpus_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save {corpus_type.value} corpus: {e}")
    
    def validate_solution(self, problem: SanskritProblem, solution: SanskritSolution) -> Dict[str, Any]:
        """
        Validate a Sanskrit solution against corpus examples.
        
        Args:
            problem: Sanskrit problem to validate
            solution: Proposed solution
            
        Returns:
            Validation results with scores and analysis
        """
        validation_result = {
            'overall_score': 0.0,
            'corpus_matches': [],
            'grammatical_accuracy': 0.0,
            'rule_compliance': 0.0,
            'linguistic_validity': 0.0,
            'detailed_analysis': {},
            'errors': []
        }
        
        try:
            # Find relevant corpus entries
            relevant_entries = self._find_relevant_entries(problem)
            
            if not relevant_entries:
                validation_result['errors'].append("No relevant corpus entries found")
                return validation_result
            
            # Validate against each relevant entry
            corpus_scores = []
            for entry in relevant_entries:
                entry_score = self._validate_against_entry(problem, solution, entry)
                corpus_scores.append(entry_score)
                validation_result['corpus_matches'].append({
                    'entry_id': entry.id,
                    'score': entry_score['total_score'],
                    'details': entry_score
                })
            
            # Calculate overall scores
            if corpus_scores:
                validation_result['overall_score'] = sum(score['total_score'] for score in corpus_scores) / len(corpus_scores)
                validation_result['grammatical_accuracy'] = sum(score['grammatical_score'] for score in corpus_scores) / len(corpus_scores)
                validation_result['rule_compliance'] = sum(score['rule_score'] for score in corpus_scores) / len(corpus_scores)
                validation_result['linguistic_validity'] = sum(score['linguistic_score'] for score in corpus_scores) / len(corpus_scores)
            
            # Add detailed analysis
            validation_result['detailed_analysis'] = self._generate_detailed_analysis(problem, solution, relevant_entries)
            
        except Exception as e:
            logger.error(f"Error validating solution: {e}")
            validation_result['errors'].append(f"Validation error: {str(e)}")
        
        return validation_result
    
    def _find_relevant_entries(self, problem: SanskritProblem) -> List[CorpusEntry]:
        """Find corpus entries relevant to the given problem."""
        relevant_entries = []
        
        # Map problem types to corpus types
        type_mapping = {
            SanskritProblemType.SANDHI_APPLICATION: CorpusType.SANDHI_EXAMPLES,
            SanskritProblemType.MORPHOLOGICAL_ANALYSIS: CorpusType.MORPHOLOGICAL_FORMS,
            SanskritProblemType.WORD_DERIVATION: CorpusType.DERIVATION_EXAMPLES,
            SanskritProblemType.COMPOUND_ANALYSIS: CorpusType.COMPOUND_EXAMPLES
        }
        
        corpus_type = type_mapping.get(problem.problem_type)
        if not corpus_type:
            return relevant_entries
        
        # Find entries with similar input patterns
        for entry in self.corpora[corpus_type]:
            if self._is_entry_relevant(problem, entry):
                relevant_entries.append(entry)
        
        # Sort by relevance (simple heuristic for now)
        relevant_entries.sort(key=lambda e: self._calculate_relevance_score(problem, e), reverse=True)
        
        # Return top 5 most relevant entries
        return relevant_entries[:5]
    
    def _is_entry_relevant(self, problem: SanskritProblem, entry: CorpusEntry) -> bool:
        """Check if a corpus entry is relevant to the problem."""
        # Simple relevance check based on text similarity
        problem_text = problem.input_text.lower()
        entry_source = entry.source_text.lower()
        
        # Check for common words or patterns
        problem_words = set(problem_text.split())
        entry_words = set(entry_source.split())
        
        # If there's significant word overlap, consider it relevant
        overlap = len(problem_words.intersection(entry_words))
        return overlap > 0 or len(problem_words) <= 2  # Always relevant for short problems
    
    def _calculate_relevance_score(self, problem: SanskritProblem, entry: CorpusEntry) -> float:
        """Calculate relevance score between problem and corpus entry."""
        problem_text = problem.input_text.lower()
        entry_source = entry.source_text.lower()
        
        # Simple Jaccard similarity
        problem_words = set(problem_text.split())
        entry_words = set(entry_source.split())
        
        intersection = len(problem_words.intersection(entry_words))
        union = len(problem_words.union(entry_words))
        
        return intersection / union if union > 0 else 0.0
    
    def _validate_against_entry(self, problem: SanskritProblem, solution: SanskritSolution, entry: CorpusEntry) -> Dict[str, float]:
        """Validate solution against a specific corpus entry."""
        scores = {
            'grammatical_score': 0.0,
            'rule_score': 0.0,
            'linguistic_score': 0.0,
            'total_score': 0.0
        }
        
        try:
            # Check grammatical accuracy
            scores['grammatical_score'] = self._check_grammatical_accuracy(solution, entry)
            
            # Check rule compliance
            scores['rule_score'] = self._check_rule_compliance(solution, entry)
            
            # Check linguistic validity
            scores['linguistic_score'] = self._check_linguistic_validity(solution, entry)
            
            # Calculate weighted total score
            scores['total_score'] = (
                scores['grammatical_score'] * 0.4 +
                scores['rule_score'] * 0.3 +
                scores['linguistic_score'] * 0.3
            )
            
        except Exception as e:
            logger.error(f"Error validating against entry {entry.id}: {e}")
        
        return scores
    
    def _check_grammatical_accuracy(self, solution: SanskritSolution, entry: CorpusEntry) -> float:
        """Check grammatical accuracy of solution against corpus entry."""
        # Compare solution output with expected target
        if hasattr(solution, 'output_text') and solution.output_text:
            expected = entry.target_text.lower().strip()
            actual = solution.output_text.lower().strip()
            
            # Simple string similarity (can be enhanced with more sophisticated metrics)
            if expected == actual:
                return 1.0
            elif expected in actual or actual in expected:
                return 0.7
            else:
                # Calculate edit distance similarity
                return self._calculate_string_similarity(expected, actual)
        
        return 0.0
    
    def _check_rule_compliance(self, solution: SanskritSolution, entry: CorpusEntry) -> float:
        """Check if solution follows the correct grammatical rules."""
        score = 0.0
        
        # Check if solution references correct sūtras
        if hasattr(solution, 'applied_rules') and solution.applied_rules:
            solution_rules = set(solution.applied_rules)
            expected_rules = set(entry.sutra_references)
            
            if expected_rules:
                overlap = len(solution_rules.intersection(expected_rules))
                score = overlap / len(expected_rules)
        
        # Check grammatical analysis consistency
        if hasattr(solution, 'grammatical_analysis') and solution.grammatical_analysis:
            analysis_score = self._compare_grammatical_analysis(
                solution.grammatical_analysis, 
                entry.grammatical_analysis
            )
            score = max(score, analysis_score)
        
        return score
    
    def _check_linguistic_validity(self, solution: SanskritSolution, entry: CorpusEntry) -> float:
        """Check linguistic validity of the solution."""
        # Use reward calculator for linguistic validation
        if hasattr(solution, 'output_text') and solution.output_text:
            reward_result = self.reward_calculator.calculate_reward(
                solution.output_text,
                entry.target_text,
                {'grammatical_analysis': entry.grammatical_analysis}
            )
            return reward_result.get('linguistic_validity', 0.0)
        
        return 0.0
    
    def _calculate_string_similarity(self, str1: str, str2: str) -> float:
        """Calculate similarity between two strings using edit distance."""
        if not str1 or not str2:
            return 0.0
        
        # Simple Levenshtein distance implementation
        len1, len2 = len(str1), len(str2)
        if len1 == 0:
            return 0.0 if len2 > 0 else 1.0
        if len2 == 0:
            return 0.0
        
        # Create distance matrix
        matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
        # Initialize first row and column
        for i in range(len1 + 1):
            matrix[i][0] = i
        for j in range(len2 + 1):
            matrix[0][j] = j
        
        # Fill the matrix
        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                cost = 0 if str1[i-1] == str2[j-1] else 1
                matrix[i][j] = min(
                    matrix[i-1][j] + 1,      # deletion
                    matrix[i][j-1] + 1,      # insertion
                    matrix[i-1][j-1] + cost  # substitution
                )
        
        # Convert distance to similarity
        max_len = max(len1, len2)
        distance = matrix[len1][len2]
        return 1.0 - (distance / max_len)
    
    def _compare_grammatical_analysis(self, analysis1: Dict[str, Any], analysis2: Dict[str, Any]) -> float:
        """Compare two grammatical analyses for similarity."""
        if not analysis1 or not analysis2:
            return 0.0
        
        # Count matching keys and values
        common_keys = set(analysis1.keys()).intersection(set(analysis2.keys()))
        if not common_keys:
            return 0.0
        
        matches = 0
        for key in common_keys:
            if analysis1[key] == analysis2[key]:
                matches += 1
        
        return matches / len(common_keys)
    
    def _generate_detailed_analysis(self, problem: SanskritProblem, solution: SanskritSolution, entries: List[CorpusEntry]) -> Dict[str, Any]:
        """Generate detailed analysis of the validation."""
        analysis = {
            'problem_type': problem.problem_type.value,
            'corpus_coverage': len(entries),
            'validation_summary': {},
            'recommendations': []
        }
        
        # Analyze common patterns in corpus entries
        rule_frequency = {}
        for entry in entries:
            for rule in entry.sutra_references:
                rule_frequency[rule] = rule_frequency.get(rule, 0) + 1
        
        analysis['common_rules'] = sorted(rule_frequency.items(), key=lambda x: x[1], reverse=True)
        
        # Generate recommendations based on validation results
        if hasattr(solution, 'applied_rules') and solution.applied_rules:
            missing_rules = set()
            for entry in entries:
                missing_rules.update(set(entry.sutra_references) - set(solution.applied_rules))
            
            if missing_rules:
                analysis['recommendations'].append(f"Consider applying rules: {', '.join(missing_rules)}")
        
        return analysis
    
    def get_corpus_statistics(self) -> Dict[str, Any]:
        """Get statistics about the loaded corpora."""
        stats = {
            'total_entries': sum(len(corpus) for corpus in self.corpora.values()),
            'corpus_breakdown': {},
            'difficulty_distribution': {},
            'rule_coverage': set()
        }
        
        for corpus_type, entries in self.corpora.items():
            stats['corpus_breakdown'][corpus_type.value] = len(entries)
            
            for entry in entries:
                # Count difficulty levels
                difficulty = entry.difficulty_level
                stats['difficulty_distribution'][difficulty] = stats['difficulty_distribution'].get(difficulty, 0) + 1
                
                # Collect all rules
                stats['rule_coverage'].update(entry.sutra_references)
        
        stats['rule_coverage'] = len(stats['rule_coverage'])
        
        return stats
    
    def add_corpus_entry(self, entry: CorpusEntry) -> bool:
        """Add a new entry to the appropriate corpus."""
        try:
            self.corpora[entry.corpus_type].append(entry)
            
            # Save updated corpus
            corpus_data = []
            for corpus_entry in self.corpora[entry.corpus_type]:
                corpus_data.append({
                    'id': corpus_entry.id,
                    'source_text': corpus_entry.source_text,
                    'target_text': corpus_entry.target_text,
                    'grammatical_analysis': corpus_entry.grammatical_analysis,
                    'sutra_references': corpus_entry.sutra_references,
                    'metadata': corpus_entry.metadata
                })
            
            self._save_corpus(entry.corpus_type, corpus_data)
            logger.info(f"Added new entry {entry.id} to {entry.corpus_type.value} corpus")
            return True
            
        except Exception as e:
            logger.error(f"Failed to add corpus entry: {e}")
            return False
    
    def validate_corpus_quality(self) -> Dict[str, Any]:
        """Validate the quality and consistency of the corpus data."""
        quality_report = {
            'total_entries': 0,
            'valid_entries': 0,
            'invalid_entries': [],
            'missing_data': [],
            'duplicate_ids': [],
            'rule_coverage_gaps': []
        }
        
        seen_ids = set()
        
        for corpus_type, entries in self.corpora.items():
            for entry in entries:
                quality_report['total_entries'] += 1
                
                # Check for duplicate IDs
                if entry.id in seen_ids:
                    quality_report['duplicate_ids'].append(entry.id)
                else:
                    seen_ids.add(entry.id)
                
                # Validate entry completeness
                is_valid = True
                missing_fields = []
                
                if not entry.source_text.strip():
                    missing_fields.append('source_text')
                    is_valid = False
                
                if not entry.target_text.strip():
                    missing_fields.append('target_text')
                    is_valid = False
                
                if not entry.grammatical_analysis:
                    missing_fields.append('grammatical_analysis')
                    is_valid = False
                
                if not entry.sutra_references:
                    missing_fields.append('sutra_references')
                    is_valid = False
                
                if is_valid:
                    quality_report['valid_entries'] += 1
                else:
                    quality_report['invalid_entries'].append({
                        'id': entry.id,
                        'corpus_type': corpus_type.value,
                        'missing_fields': missing_fields
                    })
                
                if missing_fields:
                    quality_report['missing_data'].extend([
                        f"{entry.id}: {field}" for field in missing_fields
                    ])
        
        return quality_report
    
    def export_validation_results(self, results: List[Dict[str, Any]], output_path: str) -> bool:
        """
        Export validation results to JSON file for analysis.
        
        Args:
            results: List of validation results
            output_path: Path to save the results
            
        Returns:
            True if export successful, False otherwise
        """
        try:
            export_data = {
                'timestamp': datetime.now().isoformat(),
                'corpus_statistics': self.get_corpus_statistics(),
                'validation_results': results,
                'summary': {
                    'total_validations': len(results),
                    'average_score': sum(r.get('overall_score', 0) for r in results) / len(results) if results else 0,
                    'high_scoring_count': sum(1 for r in results if r.get('overall_score', 0) > 0.8),
                    'low_scoring_count': sum(1 for r in results if r.get('overall_score', 0) < 0.3)
                }
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Exported validation results to {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to export validation results: {e}")
            return False
           